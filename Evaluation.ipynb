{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Housing Prices - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### James Mwakichako - jmwakich@hawk.iit.edu\n",
    "### Michael Baroody  - mbaroody@hawk.iit.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Before we are able to fit our model, we have to take care of missing values and categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, linear_model\n",
    "\n",
    "# train DataFrame object\n",
    "# see http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "# and http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "train = pd.read_csv(\"train.csv\", header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we had some features with many missing values. Below are all the features that have some missing values. All the other features have all values filled in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature \tProportion Values Missing\n",
      "------- \t----------------------\n",
      "PoolQC          0.995205\n",
      "MiscFeature     0.963014\n",
      "Alley           0.937671\n",
      "Fence           0.807534\n",
      "FireplaceQu     0.472603\n",
      "LotFrontage     0.177397\n",
      "GarageCond      0.055479\n",
      "GarageType      0.055479\n",
      "GarageYrBlt     0.055479\n",
      "GarageFinish    0.055479\n",
      "GarageQual      0.055479\n",
      "BsmtExposure    0.026027\n",
      "BsmtFinType2    0.026027\n",
      "BsmtFinType1    0.025342\n",
      "BsmtCond        0.025342\n",
      "BsmtQual        0.025342\n",
      "MasVnrArea      0.005479\n",
      "MasVnrType      0.005479\n",
      "Electrical      0.000685\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature \\tProportion Values Missing\")\n",
    "print(\"------- \\t----------------------\")\n",
    "\n",
    "# there are 19 features that contain missing values \n",
    "# see http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.count.html#pandas.DataFrame.count\n",
    "print((1 - (train.count() / len(train))).sort_values(ascending=False).nlargest(19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We want to throw out all features that have > 25% missing values. That means 'PoolQC', 'MiscFeature', 'Alley', 'Fence', and 'FireplaceQu' will all be excluded from the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train['PoolQC']\n",
    "del train['MiscFeature']\n",
    "del train['Alley']\n",
    "del train['Fence']\n",
    "del train['FireplaceQu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will fill in missing values for the rest of the features. For numerical features, we will to fill in the missing values with the mean for that column. For example, we know that the mean value for all of the known 'LotFrontage' values is around 70. Therefore, for all of the 'NaN' values encountered in the 'LotFrontage' column, we will replace the value with 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill in the missing numerical features with the means\n",
    "# see http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mean.html#pandas.DataFrame.mean\n",
    "# and http://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.fillna.html#pandas.Series.fillna\n",
    "means = train.mean(skipna=True)\n",
    "for feature,mean in means.iteritems():\n",
    "    train[feature] = train[feature].fillna(value=mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the categorical features, we will fill in the missing values with the mode category for that column. For example, it is known that the most frequent 'GarageQual' is 'TA.' Therefore, for all of the 'NaN' values we encounter in the 'GarageQual' column, we will replace the value with 'TA.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill in the missing categorical values with the modes\n",
    "# see http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mode.html#pandas.DataFrame.mode\n",
    "train = train.fillna(train.mode().iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must deal with the categorical variables. We do this by encoding the categorical feature labels with numbers, using sklearn.preprocessing. In the visualization phase of our project, we identified 49 categorical features. However, some of these were already encoded with numbers. The 'MoSold' feature, for example, is a categorical feature of the month the house was sold, and it is already encoded for us by the number of the month in the calendar. Therefore, we leave it alone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first, find those features that are unencoded categorical\n",
    "categorical_features = [feat for feat in train.columns.values if train[feat].dtype == 'object']\n",
    "\n",
    "# see http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html\n",
    "le = preprocessing.LabelEncoder()\n",
    "for feature in categorical_features: \n",
    "    le = le.fit(train[feature])\n",
    "    train[feature] = pd.Series(le.transform(train[feature]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we have successfully deleted features with too many missing values, filled in all other missing values, and encoded our categorical variables, we are ready to fit our model. We shall use Lasso Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight coefficients\n",
      "[ -1.66119746e+00  -1.29602605e+02  -1.24410096e+03  -1.45211548e+02\n",
      "   3.87104923e-01   2.80078001e+04  -9.22809200e+02   3.45221005e+03\n",
      "  -4.65932679e+04  -3.99360616e+01   5.81040276e+03   3.72018174e+02\n",
      "  -7.97868266e+02  -8.52625325e+03  -2.17221654e+03  -1.17298492e+03\n",
      "   1.10144555e+04   4.57642869e+03   1.84152153e+02   3.59566976e+01\n",
      "   2.35684078e+03   4.79364387e+03  -9.61174416e+02   3.46186718e+02\n",
      "   4.69590028e+03   3.14097577e+01  -9.23223168e+03   5.58599930e+02\n",
      "   1.12790617e+03  -9.07065474e+03   2.45184328e+03  -3.84213815e+03\n",
      "  -8.96370622e+02   8.88613572e+00   7.43838814e+02   1.11509560e+01\n",
      "   1.49002350e+00   1.07819462e+00  -1.85145039e+03  -7.48642437e+02\n",
      "  -6.94094825e+02  -2.82247408e+02   4.25302884e+01   4.19720946e+01\n",
      "   1.81050397e+01   5.12868229e+00   7.08554153e+03   8.76206687e+02\n",
      "   3.69514673e+03  -8.88164483e+01  -3.58946330e+03  -1.09788013e+04\n",
      "  -8.93105230e+03   3.24453047e+03   4.17764582e+03   4.62139890e+03\n",
      "  -1.23988190e+02  -2.96195481e+01  -2.61630570e+02   1.06193487e+04\n",
      "  -3.30400413e+00   2.71348422e+02   2.24320804e+03   1.10159269e+03\n",
      "   1.66475375e+01  -1.46794852e+01   5.95754232e+00   2.69163688e+01\n",
      "   4.65384147e+01  -1.65946154e+01  -5.82907381e-01  -1.73089816e+02\n",
      "  -1.12701596e+03  -5.23786643e+02   2.54926282e+03]\n",
      "\n",
      "\n",
      "Accuracy score against training data\n",
      "0.849528200926\n"
     ]
    }
   ],
   "source": [
    "# see http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn-linear-model-lasso\n",
    "# and http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html#pandas.DataFrame.drop\n",
    "clf = linear_model.Lasso(alpha=1.0)\n",
    "X = train.drop('SalePrice', 1).values\n",
    "y = train['SalePrice'].values\n",
    "clf.fit(X, y)\n",
    "\n",
    "print('Weight coefficients')\n",
    "print(clf.coef_)\n",
    "\n",
    "print('\\n\\nAccuracy score against training data')\n",
    "print(clf.score(X, y))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
