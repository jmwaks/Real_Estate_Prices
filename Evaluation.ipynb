{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Housing Prices - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### James Mwakichako - jmwakich@hawk.iit.edu\n",
    "### Michael Baroody  - mbaroody@hawk.iit.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Before we are able to fit our model, we have to take care of missing values and categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, linear_model, model_selection, neural_network\n",
    "\n",
    "# train DataFrame object\n",
    "# see http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "# and http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "train = pd.read_csv(\"train.csv\", header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we had some features with many missing values. Below are all the features that have some missing values. All the other features have all values filled in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature \tProportion Values Missing\n",
      "------- \t----------------------\n",
      "PoolQC          0.995205\n",
      "MiscFeature     0.963014\n",
      "Alley           0.937671\n",
      "Fence           0.807534\n",
      "FireplaceQu     0.472603\n",
      "LotFrontage     0.177397\n",
      "GarageCond      0.055479\n",
      "GarageType      0.055479\n",
      "GarageYrBlt     0.055479\n",
      "GarageFinish    0.055479\n",
      "GarageQual      0.055479\n",
      "BsmtExposure    0.026027\n",
      "BsmtFinType2    0.026027\n",
      "BsmtFinType1    0.025342\n",
      "BsmtCond        0.025342\n",
      "BsmtQual        0.025342\n",
      "MasVnrArea      0.005479\n",
      "MasVnrType      0.005479\n",
      "Electrical      0.000685\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature \\tProportion Values Missing\")\n",
    "print(\"------- \\t----------------------\")\n",
    "\n",
    "# there are 19 features that contain missing values \n",
    "# see http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.count.html#pandas.DataFrame.count\n",
    "print((1 - (train.count() / len(train))).sort_values(ascending=False).nlargest(19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We want to throw out all features that have > 25% missing values. That means 'PoolQC', 'MiscFeature', 'Alley', 'Fence', and 'FireplaceQu' will all be excluded from the training data. We also don't care about the 'Id' for obvious reasons, and 'Utilities' because virtually all datapoints have the same value for the 'Utilities' feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del train['PoolQC']\n",
    "del train['MiscFeature']\n",
    "del train['Alley']\n",
    "del train['Fence']\n",
    "del train['FireplaceQu']\n",
    "del train['Id']\n",
    "del train['Utilities']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the features and their respective types: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# purposefully-ordered \n",
    "ordered_categorical_features = ['OverallCond', 'Fireplaces', 'GarageCars', \n",
    "                                'TotRmsAbvGrd', 'BedroomAbvGr', 'FullBath', \n",
    "                                'BsmtFullBath', 'OverallQual', 'KitchenQual', \n",
    "                                'CentralAir', 'HeatingQC', 'BsmtCond', 'BsmtQual', \n",
    "                                'ExterCond', 'ExterQual', 'BsmtHalfBath']\n",
    "\n",
    "# arbitrarily-ordered\n",
    "unordered_categorical_features = ['MSZoning', 'Street', 'LotShape', \n",
    "                                  'LandContour', 'LotConfig', 'LandSlope', \n",
    "                                  'Neighborhood', 'Condition1', 'Condition2', \n",
    "                                  'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', \n",
    "                                  'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', \n",
    "                                  'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', \n",
    "                                  'Electrical', 'GarageFinish', 'Functional', 'GarageType', \n",
    "                                  'GarageQual', 'GarageCond', 'PavedDrive', 'SaleType', 'SaleCondition', \n",
    "                                  'MSSubClass', 'PoolArea', 'MoSold']\n",
    "\n",
    "# note choice of years as continuous \n",
    "continuous_features = ['LotFrontage', 'LotArea', 'YearBuilt', \n",
    "                       'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', \n",
    "                       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "                       '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', \n",
    "                       'GrLivArea', 'HalfBath', 'KitchenAbvGr', \n",
    "                       'GarageYrBlt', 'GarageArea', 'WoodDeckSF', \n",
    "                       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', \n",
    "                       'ScreenPorch', 'MiscVal', 'YrSold']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to encode ordered categorical features in such a way that reflects their class heirarchy and unordered categorical features in such a way that each class is equidistant from each other class using OneHotEncoder. \n",
    "\n",
    "But first we must fill in the missing ('Nan') values. For numerical features, we will to fill in the missing values with the mean for that column. For example, we know that the mean value for all of the known 'LotFrontage' values is around 70. Therefore, for all of the 'NaN' values encountered in the 'LotFrontage' column, we will replace the value with 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means = {feat:np.nanmean(train[feat].values) for feat in continuous_features}\n",
    "for feature,mean in means.items():\n",
    "    train[feature] = train[feature].fillna(value=mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the categorical features, we will fill in the missing values with the mode category for that column. For example, it is known that the most frequent 'GarageQual' is 'TA.' Therefore, for all of the 'NaN' values we encounter in the 'GarageQual' column, we will replace the value with 'TA.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill in the missing categorical values with the modes \n",
    "categorical_features = unordered_categorical_features + ordered_categorical_features\n",
    "modes = {feat:train[feat].mode()[0] for feat in categorical_features}\n",
    "for feature,mode in modes.items():\n",
    "    train[feature] = train[feature].fillna(value=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must encode the categorical variables. The unordered categorical features need to be transformed using the OneHotEncoder (expanding our data using pandas.get_dummies). Some categorical features need special treatement. Many of the ordered categorical variables are already encoded. For example, 'OverallCond.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simple encoding scheme much like http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder\n",
    "for feat in unordered_categorical_features:\n",
    "    dummies = pd.get_dummies(train[feat], prefix=feat)\n",
    "    train[dummies.columns] = dummies\n",
    "    train = train.drop(feat, 1)\n",
    "\n",
    "\n",
    "# some ordered categorical need special treatement\n",
    "special_encode = ['KitchenQual','HeatingQC','BsmtCond', \n",
    "                 'ExterCond', 'ExterQual', 'CentralAir']\n",
    "\n",
    "\n",
    "\n",
    "CondKey = {\n",
    "        # answer not available (0 weight)\n",
    "        'TA' : 0,\n",
    "        # Poor \n",
    "        'Po' : 1,\n",
    "        # Fair\n",
    "        'Fa' : 1,\n",
    "        # Good\n",
    "        'Gd' : 2,\n",
    "        # Excellent\n",
    "        'Ex' : 3\n",
    "}\n",
    "\n",
    "BinKey = {\n",
    "    # No\n",
    "    'N' : 0,\n",
    "    # Yes\n",
    "    'Y' : 1\n",
    "}\n",
    "\n",
    "def encode(data, key):\n",
    "    return np.array([key[d] for d in data])\n",
    "\n",
    "train['KitchenQual'] = encode(train['KitchenQual'], CondKey)\n",
    "train['HeatingQC'] = encode(train['HeatingQC'], CondKey)\n",
    "train['BsmtCond'] = encode(train['BsmtCond'], CondKey)\n",
    "train['BsmtQual'] = encode(train['BsmtQual'], CondKey)\n",
    "train['ExterCond'] = encode(train['ExterCond'], CondKey)\n",
    "train['ExterQual'] = encode(train['ExterQual'], CondKey)\n",
    "train['CentralAir'] = encode(train['CentralAir'], BinKey)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we have successfully deleted features with too many missing values, filled in all other missing values, and encoded our categorical variables, we are ready to fit our model. We shall use Lasso Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbaroody/anaconda3/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier\t\t\tAverage Cross-Validation Score (k=10 folds)\n",
      "----------\t\t\t-------------------------------------------\n",
      "Lasso\t\t\t\t0.815\n",
      "Linear\t\t\t\t-4050743.415\n",
      "MLP\t\t\t\t0.396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mbaroody/anaconda3/lib/python3.5/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# and http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html#pandas.DataFrame.drop\n",
    "X = train.drop('SalePrice', 1).values\n",
    "y = train['SalePrice'].values\n",
    "\n",
    "# see http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn-linear-model-lasso\n",
    "#lasso = linear_model.Lasso(alpha=6.0)\n",
    "#lasso_average_score = np.mean(model_selection.cross_val_score(lasso, X, y, cv=10, scoring='r2'))\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression\n",
    "linReg = linear_model.LinearRegression()\n",
    "linReg_average_score = np.mean(model_selection.cross_val_score(linReg, X, y, cv=10, scoring='r2'))\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier\n",
    "mlp = neural_network.MLPRegressor()\n",
    "mlp_average_score = np.mean(model_selection.cross_val_score(mlp, X, y, cv=2, scoring='r2'))\n",
    "\n",
    "print('Classifier\\t\\t\\tAverage Cross-Validation Score (k=10 folds)')\n",
    "print('----------\\t\\t\\t-------------------------------------------')\n",
    "print('Lasso\\t\\t\\t\\t%0.3f' % lasso_average_score)\n",
    "print('Linear\\t\\t\\t\\t%0.3f' % linReg_average_score)\n",
    "print('MLP\\t\\t\\t\\t%0.3f' % mlp_average_score)\n",
    "#print('MLP\\t\\t\\t%d' % mlp_average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
