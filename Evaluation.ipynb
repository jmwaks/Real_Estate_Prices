{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Housing Prices - Advanced Regression Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### James Mwakichako - jmwakich@hawk.iit.edu\n",
    "### Michael Baroody  - mbaroody@hawk.iit.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to predict the final sale price of a home, given features of a house such as square footage, number of pools, garage condition, etc. Initially, we are given 80 features and 1460 datapoints. Of course, not all of this data is clean. There are several problems with our dataset:\n",
    "\n",
    "* missing values\n",
    "* NaN values\n",
    "* categorical data that needs to be encoded.\n",
    "\n",
    "This document outlines some of the approaches that we took to deal with these issues as well as the models we used to fit our processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a widget that you might find helpful when navigating through our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent values missing: 93.767123%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEZCAYAAACU3p4jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff844b30fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, linear_model, model_selection, neural_network, ensemble, tree\n",
    "\n",
    "# train DataFrame object\n",
    "# see http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html\n",
    "# and http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\n",
    "train = pd.read_csv(\"train.csv\", header = 0)\n",
    "\n",
    "features = [feature for feature in train.columns.values]\n",
    "\n",
    "features_dropdown = widgets.Dropdown(\n",
    "    options=sorted(features),\n",
    "    value='TotalBsmtSF',\n",
    "    description='Feature',\n",
    "    disabled=False,\n",
    "    button_style='info'\n",
    ")\n",
    "\n",
    "categorical_features = [cat_feature for cat_feature in train.columns.values if train[cat_feature].dtype == 'object']\n",
    "categorical_features.extend(['MSSubClass', 'OverallQual', 'OverallCond', 'BsmtFullBath', \n",
    "                             'BsmtHalfBath', 'BedroomAbvGr', 'KitchenAbvGr', \n",
    "                             'TotRmsAbvGr', 'Fireplaces', 'GarageCars', 'MoSold', 'YrSold'])\n",
    "\n",
    "\n",
    "def display_stats(feature):\n",
    "    \n",
    "    if feature in categorical_features:\n",
    "        stringified = train[feature].apply(lambda x: str(x)).values\n",
    "        print(\"Percent values missing: %f%%\" % (100*(np.sum(stringified == 'nan') / len(train[feature].values))))\n",
    "        \n",
    "        nan_indices = np.where(stringified == 'nan')[0]\n",
    "        stringified = np.delete(stringified, nan_indices)\n",
    "        \n",
    "        labels = np.unique(stringified)\n",
    "        data = [np.sum(stringified == l) for l in labels]\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        ax.set_title('Visualization of %s' % feature)\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel('Frequency')\n",
    "        if feature == 'MoSold':\n",
    "            labels = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "        ax.bar(range(len(data)), data, tick_label=labels)\n",
    "        #ax.xticks(range(len(lables)), labels)\n",
    "        plt.show()\n",
    "    else:\n",
    "        x = train[feature].values\n",
    "    \n",
    "        #find zero indices\n",
    "        zero_indices = np.where(x == 0)[0]\n",
    "        nan_indices = np.where(np.isnan(x))[0]\n",
    "        #delete these datapoints from x and y\n",
    "    \n",
    "        x = np.delete(x, zero_indices)\n",
    "        x = np.delete(x, nan_indices)\n",
    "        \n",
    "        print('Mean: %.2f' % np.mean(x))\n",
    "        print('Variance: %.2f' % np.var(x))\n",
    "        # we don't count zeros as missing\n",
    "        print('Percent values missing: %f%%' % (100*((len(nan_indices)) / len(train[feature].values))))\n",
    "    \n",
    "        fig1 = plt.figure(1)\n",
    "        ax1 = fig1.add_subplot(1, 1, 1)\n",
    "        ax1.set_title('Histogram of %s' % feature)\n",
    "        ax1.set_xlabel(feature)\n",
    "        ax1.set_ylabel('Frequency')\n",
    "        ax1.hist(x)\n",
    "        \n",
    "        fig2 = plt.figure(2)\n",
    "        ax2= fig2.add_subplot(1, 1, 1)\n",
    "        ax2.set_title('Boxplot of %s' % feature)\n",
    "        ax2.boxplot([list(x)], labels=[feature])\n",
    "        plt.show()\n",
    "\n",
    "widgets.interact(display_stats, feature=features_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Step 1 - Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we had some features with many missing values (refer to widget above). We want to throw out all features that have > 25% missing values. That means 'PoolQC', 'MiscFeature', 'Alley', 'Fence', and 'FireplaceQu' will all be excluded from the training data. We also don't care about the 'Id' for obvious reasons, and 'Utilities' because virtually all datapoints have the same value for the 'Utilities' feature (again, refer to widget). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 74)\n"
     ]
    }
   ],
   "source": [
    "del train['PoolQC']\n",
    "del train['MiscFeature']\n",
    "del train['Alley']\n",
    "del train['Fence']\n",
    "del train['FireplaceQu']\n",
    "del train['Id']\n",
    "del train['Utilities']\n",
    "\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Step 2 - Sorting Feature Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to separate our data into three types: ordered categorical data (scales of 1-10, condition ratings, etc), unordered categorical data, and continuous data. Note that we included some features in the continuous set that could be considered categorical (like the 'YearSo'). Our reasons for separating the data as we did should be obvious when you inspect their distribution with the widget. Below are the features and their respective types: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# purposefully-ordered \n",
    "ordered_categorical_features = ['OverallCond', 'Fireplaces', 'GarageCars', \n",
    "                                'TotRmsAbvGrd', 'BedroomAbvGr', 'FullBath', \n",
    "                                'BsmtFullBath', 'OverallQual', 'KitchenQual', \n",
    "                                'CentralAir', 'HeatingQC', 'BsmtCond', 'BsmtQual', \n",
    "                                'ExterCond', 'ExterQual', 'BsmtHalfBath', 'GarageCond',\n",
    "                                'GarageQual']\n",
    "\n",
    "# arbitrarily-ordered\n",
    "unordered_categorical_features = ['MSZoning', 'Street', 'LotShape', \n",
    "                                  'LandContour', 'LotConfig', 'LandSlope', \n",
    "                                  'Neighborhood', 'Condition1', 'Condition2', \n",
    "                                  'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', \n",
    "                                  'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', \n",
    "                                  'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', \n",
    "                                  'Electrical', 'GarageFinish', 'Functional', 'GarageType', \n",
    "                                  'PavedDrive', 'SaleType', 'SaleCondition', \n",
    "                                  'MSSubClass', 'PoolArea', 'MoSold']\n",
    "\n",
    "# note choice of years as continuous \n",
    "continuous_features = ['LotFrontage', 'LotArea', 'YearBuilt', \n",
    "                       'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', \n",
    "                       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "                       '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', \n",
    "                       'GrLivArea', 'HalfBath', 'KitchenAbvGr',\n",
    "                       'GarageYrBlt', 'GarageArea', 'WoodDeckSF', \n",
    "                       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', \n",
    "                       'ScreenPorch', 'MiscVal', 'YrSold']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Step 3 - Imputing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we must fill in the missing ('NaN') values. For the continuous features, we will want to fill in the missing values with the mean for that column. For example, we know that the mean value for all of the known 'LotFrontage' values is around 70. Therefore, for all of the 'NaN' values encountered in the 'LotFrontage' column, we will replace the value with 70."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means = {feat:np.nanmean(train[feat].values) for feat in continuous_features}\n",
    "for feature,mean in means.items():\n",
    "    train[feature] = train[feature].fillna(value=mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the categorical features (unordered and ordered), we will fill in the missing values with the mode category for that column. For example, it is known that the most frequent 'GarageQual' is 'TA.' Therefore, for all of the 'NaN' values we encounter in the 'GarageQual' column, we will replace the value with 'TA.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fill in the missing categorical values with the modes \n",
    "categorical_features = unordered_categorical_features + ordered_categorical_features\n",
    "modes = {feat:train[feat].mode()[0] for feat in categorical_features}\n",
    "for feature,mode in modes.items():\n",
    "    train[feature] = train[feature].fillna(value=mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Step 3 - Encoding Categorical Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must encode the categorical features. The unordered categorical features need to be transformed using a similar approach to OneHotEncoder (but using pandas.get_dummies). Some ordered categorical features need special treatement (i.e. they are of dtype='object'). However, many of the ordered categorical variables are already encoded. For example, 'OverallCond' (see widget). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# similar to OneHotEncoder, this section of code will pass through all \n",
    "# unordered categorical features, expanding the training data by \n",
    "# numCols columns, where numCols = len(train[feat].columns)\n",
    "# each coll\n",
    "for feat in unordered_categorical_features:\n",
    "    dummies = pd.get_dummies(train[feat], prefix=feat)\n",
    "    train[dummies.columns] = dummies\n",
    "    train = train.drop(feat, 1)\n",
    "\n",
    "# simple encoding scheme much like http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder\n",
    "# however, we enforce order with custom encoder\n",
    "special_encode = ['KitchenQual','HeatingQC','BsmtCond', \n",
    "                 'ExterCond', 'ExterQual', 'CentralAir']\n",
    "\n",
    "CondKey = {\n",
    "        # answer not available (0 weight)\n",
    "        'TA' : 0,\n",
    "        # Poor \n",
    "        'Po' : 1,\n",
    "        # Fair\n",
    "        'Fa' : 1,\n",
    "        # Good\n",
    "        'Gd' : 2,\n",
    "        # Excellent\n",
    "        'Ex' : 3\n",
    "}\n",
    "\n",
    "BinKey = {\n",
    "    # No\n",
    "    'N' : 0,\n",
    "    # Yes\n",
    "    'Y' : 1\n",
    "}\n",
    "\n",
    "def encode(data, key):\n",
    "    return np.array([key[d] for d in data])\n",
    "\n",
    "train['KitchenQual'] = encode(train['KitchenQual'], CondKey)\n",
    "train['HeatingQC'] = encode(train['HeatingQC'], CondKey)\n",
    "train['BsmtCond'] = encode(train['BsmtCond'], CondKey)\n",
    "train['BsmtQual'] = encode(train['BsmtQual'], CondKey)\n",
    "train['ExterCond'] = encode(train['ExterCond'], CondKey)\n",
    "train['ExterQual'] = encode(train['ExterQual'], CondKey)\n",
    "train['GarageCond'] = encode(train['GarageCond'], CondKey)\n",
    "train['GarageQual'] = encode(train['GarageQual'], CondKey)\n",
    "train['CentralAir'] = encode(train['CentralAir'], BinKey)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now that we have successfully deleted features with too many missing values, filled in all other missing values, and encoded our categorical variables, we are ready to fit our models. We use the following models and print their scoring results using the 'R2' performance metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier\t\t\tCross Val Score Average (folds=10)\n",
      "----------\t\t\t-------------------------------------------\n",
      "Lasso\t\t\t\t0.824\n",
      "Linear\t\t\t\t0.824\n",
      "Random Forest\t\t\t0.848\n",
      "Ada Boost\t\t\t0.802\n",
      "Decision Tree\t\t\t0.701\n",
      "Gradient Boosting\t\t0.892\n"
     ]
    }
   ],
   "source": [
    "# and http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.drop.html#pandas.DataFrame.drop\n",
    "X = train.drop('SalePrice', 1).values\n",
    "y = train['SalePrice'].values\n",
    "\n",
    "# see http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html#sklearn-linear-model-lasso\n",
    "lasso = linear_model.Lasso(alpha=10.0)\n",
    "lasso_avg = np.mean(model_selection.cross_val_score(lasso, X, y, cv=10, scoring='r2'))\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression\n",
    "linReg = linear_model.LinearRegression()\n",
    "linReg_avg = np.mean(model_selection.cross_val_score(lasso, X, y, cv=10, scoring='r2'))\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "forest = ensemble.RandomForestRegressor()\n",
    "forest_avg = np.mean(model_selection.cross_val_score(forest, X, y, cv=10, scoring='r2'))\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html\n",
    "ada = ensemble.AdaBoostRegressor()\n",
    "ada_avg = np.mean(model_selection.cross_val_score(ada, X, y, cv=10, scoring='r2'))\n",
    "\n",
    "gradient = ensemble.GradientBoostingRegressor()\n",
    "gradient_avg = np.mean(model_selection.cross_val_score(gradient, X, y, cv=10, scoring='r2'))\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "decision = tree.DecisionTreeRegressor()\n",
    "decision_avg = np.mean(model_selection.cross_val_score(decision, X, y, cv=10, scoring='r2'))\n",
    "\n",
    "\n",
    "print('Classifier\\t\\t\\tCross Val Score Average (folds=10)')\n",
    "print('----------\\t\\t\\t-------------------------------------------')\n",
    "print('Lasso\\t\\t\\t\\t%0.3f' % lasso_avg)\n",
    "print('Linear\\t\\t\\t\\t%0.3f' % linReg_avg)\n",
    "print('Random Forest\\t\\t\\t%0.3f' % forest_avg)\n",
    "print('Ada Boost\\t\\t\\t%0.3f' % ada_avg)\n",
    "print('Decision Tree\\t\\t\\t%0.3f' % decision_avg)\n",
    "print('Gradient Boosting\\t\\t%0.3f' % gradient_avg)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
